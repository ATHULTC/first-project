# -*- coding: utf-8 -*-
"""CNN ASSIGNMENT_ATHUL_CIFAR100.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16M-XVjGihWBGILc9tAGR4SPWqLHNZ3Xq
"""

# Importing Necessary Libraries

from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten
from keras.utils import to_categorical
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar100

# Loading the Dataset

(X_train, y_train), (X_test, y_test) = cifar100.load_data()

print("X_train shape :", X_train.shape)
print("y_train shape :", y_train.shape)
print("X_test shape  :", X_test.shape)
print("y_test shape  :", y_test.shape)

X_train[0]

plt.imshow(X_train[0])
plt.show()

y_train[0]

# Performing Data Pre-Processing

## Building the input vector from the 32x32 pixels

X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)
X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)
X_train = X_train.astype('float64')
X_test = X_test.astype('float64')

# Normalizing the Images

# normalizing the data to help with the training
X_train /= 255
X_test /= 255

X_train[0]

# Performing One-Hot encoding using keras' numpy-related utilities

n_classes = 100
print("Shape before one-hot encoding : ", y_train.shape)
Y_train = to_categorical(y_train, n_classes)
Y_test  =  to_categorical(y_test, n_classes)
print("Shape after one-hot encoding  : ", Y_train.shape)

y_train[0]

Y_train[0]

# Building the CNN Model

# sequential layer
model = Sequential()
# convolutional layer
model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(32,32,3)))
model.add(MaxPool2D(pool_size=(1,1)))
# flatten output of convolutional layer
model.add(Flatten())
# hidden layer
model.add(Dense(100, activation='relu'))
# output layer
model.add(Dense(100, activation='softmax'))

# Summarizing the Model

model.summary(line_length=100)

# Compiling the Model

# compiling the sequential model
model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')

# Training the Model

model.fit(X_train, Y_train, batch_size=128, epochs=30)

# Evaluating the Model

test_loss, test_acc = model.evaluate(X_test, Y_test)

print('Model Accuracy :', test_acc)
print('Model Loss     :', test_loss)

# Performing the Prediction using the Trained Model

X_test[0]

plt.imshow(X_test[0])
plt.show()

X_test[0].shape

model.predict(X_test[0].reshape(1,32,32,3))

np.argmax(model.predict(X_test[0].reshape(1,32,32,3)))

